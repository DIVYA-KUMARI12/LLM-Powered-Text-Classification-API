# LLM-powered Text Classification API
This project implements a text classification service powered by Large Language Models (LLMs) using FastAPI.
It supports classification, feedback collection, and metrics tracking with evaluation on a benchmark dataset.


---

ğŸš€ Features

/classify â†’ Classify text into predefined categories

/feedback â†’ Collect human feedback on predictions

/metrics â†’ View usage, performance, and feedback statistics

Evaluation harness â†’ Computes accuracy, precision, recall, F1

ğŸ“‚ Project Structure

AI-Engineer-Assignment-Tagbox/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ routes/              # API endpoints
â”‚   â”‚   â”œâ”€â”€ classify.py
â”‚   â”‚   â”œâ”€â”€ feedback.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”œâ”€â”€ telemetry/           # Metrics and logging
â”‚   â””â”€â”€ prompts/             # Baseline and improved prompts
â”‚
â”‚â”€â”€ eval/
â”‚   â”œâ”€â”€ dataset.jsonl        # Evaluation dataset
â”‚   â”œâ”€â”€ run.py               # Evaluation harness
â”‚   â””â”€â”€ __init__.py
â”‚
â”‚â”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py          # Unit tests for API
â”‚   â””â”€â”€ __init__.py
â”‚
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md

âš™ï¸ Installation & Setup

# Clone the repo
git clone https://github.com/DIVYA-KUMARI12/AI-Engineer-Assignment-Tagbox.git
cd AI-Engineer-Assignment-Tagbox

# Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate   
# on Linux/Mac
venv\Scripts\activate      
# on Windows

# Install dependencies
pip install -r requirements.txt

# Run the FastAPI server
uvicorn app.main:app --reload

API will be available at:
ğŸ‘‰ http://127.0.0.1:8000

ğŸ“Œ API Endpoints

1. POST /classify

Request:
{
  "text": "The stock market crashed yesterday"
}

Response:
{
  "label": "Finance",
  "confidence": 0.89
}

2. POST /feedback

Request:
{
  "text": "The stock market crashed yesterday",
  "predicted": "Finance",
  "correct": "Economy"
}

Response:
{
  "message": "Feedback recorded"
}

3. GET /metrics

Response:
{
  "total_requests": 120,
  "class_distribution": {"Sports": 30, "Politics": 40, "Finance": 50},
  "feedback_counts": {"correct": 90, "incorrect": 30},
  "latency": {"avg_ms": 120, "p95_ms": 300}
}

ğŸ“ Prompt Design

Baseline Prompt (Zero-shot)

Classify the following text into categories: Sports, Politics, Finance, Technology.
Text: {input}

Improved Prompt (Few-shot with role)

You are an expert text classification system.  
Classify the text into **Sports, Politics, Finance, or Technology**.  
Here are examples:
- "The government passed a new law" â†’ Politics  
- "Apple released a new iPhone" â†’ Technology  
- "The stock market crashed yesterday" â†’ Finance  
- "The team won the championship" â†’ Sports  

Now classify: {input}

ğŸ“Š Evaluation

Run evaluation:

python eval/run.py

Expected metrics (fill after running):

Metric	Baseline Prompt	Improved Prompt

Accuracy	PLACEHOLDER	PLACEHOLDER
Precision	PLACEHOLDER	PLACEHOLDER
Recall	PLACEHOLDER	PLACEHOLDER
F1 Score	PLACEHOLDER	PLACEHOLDER

---

âœ… Tests

Run tests with:

pytest tests/

---

ğŸ” Design Trade-offs & Limitations

Trade-offs

Few-shot prompts increase accuracy but add latency

Feedback stored in memory (for demo) â€“ not persistent in production


Limitations

Uses mock classification (replace with real LLM for production)

Metrics reset on server restart

Dataset limited to small JSONL file

---

ğŸ‘©â€ğŸ’» Author

Divya Kumari

LinkedIn

GitHub

---

âœ¨ This project was built as part of the AI Engineer Assignment (Tagbox).
